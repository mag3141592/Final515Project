"""
Includes method for downloading datasets.
"""
import pandas as pd

from . import get_calendar_summary

from . import convert_to_matrix

from . import get_cleaned_listings

from . import sentiment

def download_dataset(dataset_dict, filename, write_csv=False):
    """
    Takes in strings of the dataset's city, state_abbv, country, filename, and date complied
    (formated as yyyy-mm-dd) and the filename. It returns the dataset as a dataframe.
    If write_csv = True, creates a csv file of the data in the directory.
    """
    date = dataset_dict['date']
    city = dataset_dict['city'].lower()
    state = dataset_dict['state'].lower()
    country = dataset_dict['country'].replace(' ', '-').lower()
    data_url = ('http://data.insideairbnb.com/' + country + '/' + state + '/'
                + city + '/' + date + '/data/' + filename)
    dataframe = pd.read_csv(data_url)

    if write_csv:
        csv_name = filename.strip('.gz')
        dataframe.to_csv('../data/' + csv_name, index=False)

    return dataframe

def generate_cleaned_data(listings, listings_columns, reviews, calendar):
    """
    Runs the cleaning and data-retrieving scripts for listings, reviews, and calendar.
    Creates CSV files.
    CSV files must already exist by running download_dataset first.
    """

    # Clean listings
    clean_listings = get_cleaned_listings.get_listings_dataframe(listings, listings_columns,
                                                                 write_csv=True)

    # convert Listings to convert_to_matrix
    convert_to_matrix.to_matrix(clean_listings)

    # run sentiment analysis
    reviews_dataset = reviews.dropna()
    sentiment_scores = sentiment.polarity(reviews_dataset, 'comments')
    sentiment.summarize_sentiment(sentiment_scores, ['listing_id'], 'compound')

    # run calendar_summary
    get_calendar_summary.create_calendar_price_averages(calendar)

def merge_data():
    """
    Merges the cleaned data into one csv file.
    Creates CSV file.
    Cleaned CSV files must be generated by running generate_cleaned_data first.
    """
    clean_listings = pd.read_csv('../../data/clean_listings.csv')
    reviews = pd.read_csv('../../data/reviews_sa_summarized.csv')
    calendar = pd.read_csv('../../data/calendar_price_averages.csv')

    merged1 = clean_listings.merge(reviews, on='listing_id')
    final_merged = merged1.merge(calendar, on='listing_id')
    final_merged.to_csv('../../data/final_merged.csv', index=False)

    return final_merged
